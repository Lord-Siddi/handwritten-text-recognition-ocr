{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug0GNgLtmCAp"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# HANDWRITTEN TEXT RECOGNITION (CTC-based CNN + BiLSTM model)\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install datasets tensorflow==2.15.0 opencv-python pillow --quiet\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from datasets import load_dataset\n",
        "import itertools\n",
        "import re\n",
        "\n",
        "# ========================\n",
        "# 0) GLOBALS\n",
        "# ========================\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "IMG_H = 64\n",
        "IMG_W = 800\n",
        "BATCH_SIZE = 16\n",
        "MAX_LABEL_LEN_CAP = 80\n",
        "\n",
        "# ========================\n",
        "# 1) LOAD DATASET (IAM-line only)\n",
        "# ========================\n",
        "print(\"Loading teklia/IAM-line ...\")\n",
        "ds = load_dataset(\"teklia/IAM-line\")\n",
        "train_split = ds[\"train\"]\n",
        "test_split  = ds[\"test\"]\n",
        "\n",
        "print(\"Train samples:\", len(train_split), \" Test samples:\", len(test_split))\n",
        "\n",
        "# ========================\n",
        "# 2) BUILD VOCAB FROM TRAIN TEXTS\n",
        "# ========================\n",
        "def collect_texts(split):\n",
        "    texts = []\n",
        "    for s in split:\n",
        "        t = s[\"text\"]\n",
        "        if t is None: t = \"\"\n",
        "        texts.append(t)\n",
        "    return texts\n",
        "\n",
        "train_texts = collect_texts(train_split)\n",
        "test_texts  = collect_texts(test_split)\n",
        "\n",
        "# Build vocab (letters, digits, punctuation)\n",
        "all_text = \"\".join(train_texts)\n",
        "vocab = sorted(set(all_text))\n",
        "vocab = [c for c in vocab if c not in [\"\\n\", \"\\r\", \"\\t\"]]\n",
        "print(\"Vocab size (from train):\", len(vocab))\n",
        "\n",
        "num_chars = len(vocab)\n",
        "\n",
        "char_to_num = layers.StringLookup(\n",
        "    vocabulary=vocab,\n",
        "    mask_token=None,\n",
        "    oov_token=\"[UNK]\"\n",
        ")\n",
        "blank_index = len(char_to_num.get_vocabulary())\n",
        "num_classes = blank_index + 1\n",
        "\n",
        "num_to_char = layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(),\n",
        "    invert=True,\n",
        "    mask_token=None\n",
        ")\n",
        "\n",
        "# ========================\n",
        "# 3) FIXED IMAGE PREPROCESSING (NO CLIPPING)\n",
        "# ========================\n",
        "def preprocess_image(pil_img: Image.Image):\n",
        "    \"\"\"\n",
        "    Resizes image keeping aspect ratio and ensures both height <= IMG_H and width <= IMG_W.\n",
        "    Pads with white if smaller; no clipping ever occurs.\n",
        "    \"\"\"\n",
        "    img = pil_img.convert(\"L\")  # grayscale\n",
        "    orig_w, orig_h = img.size\n",
        "\n",
        "    # scale so both dimensions fit within limits\n",
        "    scale_h = IMG_H / orig_h\n",
        "    scale_w = IMG_W / orig_w\n",
        "    scale = min(scale_h, scale_w)\n",
        "\n",
        "    new_w = max(1, int(round(orig_w * scale)))\n",
        "    new_h = max(1, int(round(orig_h * scale)))\n",
        "    img = img.resize((new_w, new_h), Image.BILINEAR)\n",
        "\n",
        "    arr = np.array(img).astype(\"float32\") / 255.0\n",
        "\n",
        "    # vertical pad (centered)\n",
        "    if new_h < IMG_H:\n",
        "        pad_top = (IMG_H - new_h) // 2\n",
        "        pad_bottom = IMG_H - new_h - pad_top\n",
        "        arr = np.pad(arr, ((pad_top, pad_bottom), (0, 0)), constant_values=1.0)\n",
        "\n",
        "    # horizontal pad (right side)\n",
        "    if new_w < IMG_W:\n",
        "        pad_right = IMG_W - new_w\n",
        "        arr = np.pad(arr, ((0, 0), (0, pad_right)), constant_values=1.0)\n",
        "\n",
        "    arr = np.expand_dims(arr, axis=-1)\n",
        "    return arr, new_w\n",
        "\n",
        "\n",
        "# ========================\n",
        "# 4) PREPARE DATA SPLITS\n",
        "# ========================\n",
        "def prepare_split(split):\n",
        "    images, widths, labels = [], [], []\n",
        "    for s in split:\n",
        "        img, new_w = preprocess_image(s[\"image\"])\n",
        "        images.append(img)\n",
        "        widths.append(min(new_w, IMG_W))\n",
        "        labels.append(s[\"text\"] if s[\"text\"] is not None else \"\")\n",
        "    return np.array(images, dtype=np.float32), np.array(widths, dtype=np.int32), labels\n",
        "\n",
        "train_images, train_widths, train_labels = prepare_split(train_split)\n",
        "test_images,  test_widths,  test_labels  = prepare_split(test_split)\n",
        "\n",
        "# Split into train/val\n",
        "num_train = int(0.9 * len(train_images))\n",
        "perm = np.random.permutation(len(train_images))\n",
        "tr_idx, va_idx = perm[:num_train], perm[num_train:]\n",
        "\n",
        "X_tr, W_tr, y_tr = train_images[tr_idx], train_widths[tr_idx], [train_labels[i] for i in tr_idx]\n",
        "X_va, W_va, y_va = train_images[va_idx], train_widths[va_idx], [train_labels[i] for i in va_idx]\n",
        "\n",
        "print(\"Shapes  Train:\", X_tr.shape, \" Val:\", X_va.shape, \" Test:\", test_images.shape)\n",
        "\n",
        "# ========================\n",
        "# 5) ENCODE LABELS FOR CTC\n",
        "# ========================\n",
        "def encode_label(txt, max_len):\n",
        "    seq = char_to_num(tf.strings.unicode_split(txt, \"UTF-8\"))\n",
        "    seq = seq[:max_len]\n",
        "    pad_len = max_len - tf.shape(seq)[0]\n",
        "    seq = tf.pad(seq, [[0, pad_len]], constant_values=-1)\n",
        "    return tf.cast(seq, tf.int32)\n",
        "\n",
        "max_label_len = min(max(len(t) for t in y_tr), MAX_LABEL_LEN_CAP)\n",
        "print(\"Max label length used:\", max_label_len)\n",
        "\n",
        "def batch_encode(texts):\n",
        "    return tf.stack([encode_label(t, max_label_len) for t in texts], axis=0)\n",
        "\n",
        "# ========================\n",
        "# 6) DATA GENERATOR\n",
        "# ========================\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, images, widths, labels, batch_size=BATCH_SIZE):\n",
        "        self.images = images\n",
        "        self.widths = widths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(images))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ids = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        batch_imgs = self.images[ids]\n",
        "        batch_txt  = [self.labels[i] for i in ids]\n",
        "        batch_lbl  = batch_encode(batch_txt)\n",
        "        return batch_imgs, batch_lbl\n",
        "\n",
        "train_gen = DataGenerator(X_tr, W_tr, y_tr)\n",
        "val_gen   = DataGenerator(X_va, W_va, y_va)\n",
        "\n",
        "# ========================\n",
        "# 7) MODEL (CNN + BiLSTM + CTC)\n",
        "# ========================\n",
        "def build_model():\n",
        "    inp = layers.Input(shape=(IMG_H, IMG_W, 1), name=\"image\")\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(inp)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2,1))(x)\n",
        "\n",
        "    x = layers.Conv2D(512, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2,1))(x)\n",
        "\n",
        "    H_prime = IMG_H // 16\n",
        "    W_prime = IMG_W // 4\n",
        "    C = 512\n",
        "\n",
        "    x = layers.Permute((2,1,3))(x)\n",
        "    x = layers.Reshape((W_prime, H_prime*C))(x)\n",
        "\n",
        "    x = layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(x)\n",
        "\n",
        "    logits = layers.Dense(num_classes, activation=\"softmax\", name=\"softmax\")(x)\n",
        "    return keras.Model(inp, logits, name=\"htr_cnn_bilstm_ctc\")\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "# ========================\n",
        "# 8) CTC LOSS\n",
        "# ========================\n",
        "@tf.function\n",
        "def ctc_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.int32)\n",
        "    label_len = tf.reduce_sum(tf.cast(y_true != -1, tf.int32), axis=1)\n",
        "    label_len = tf.expand_dims(label_len, 1)\n",
        "    blank = tf.cast(blank_index, tf.int32)\n",
        "    y_true = tf.where(tf.equal(y_true, -1), blank, y_true)\n",
        "    batch_size = tf.shape(y_pred)[0]\n",
        "    time_steps = tf.shape(y_pred)[1]\n",
        "    input_len = tf.fill([batch_size, 1], time_steps)\n",
        "    return keras.backend.ctc_batch_cost(y_true, y_pred, input_len, label_len)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=ctc_loss)\n",
        "\n",
        "# ========================\n",
        "# 9) TRAIN\n",
        "# ========================\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_loss\"),\n",
        "    keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ========================\n",
        "# 10) INFERENCE + GREEDY DECODE\n",
        "# ========================\n",
        "pred_model = keras.Model(model.input, model.get_layer(\"softmax\").output)\n",
        "\n",
        "def decode_batch(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    results, _ = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)\n",
        "    decoded = []\n",
        "    for r in results[0]:\n",
        "        r = tf.gather(r, tf.where(r != -1))\n",
        "        txt = tf.strings.reduce_join(num_to_char(r)).numpy().decode(\"utf-8\")\n",
        "        decoded.append(txt)\n",
        "    return decoded\n",
        "\n",
        "def collapse_repeats(text):\n",
        "    return ''.join(ch for ch, _ in itertools.groupby(text))\n",
        "\n",
        "# Test few samples\n",
        "sample_imgs = test_images[:5]\n",
        "preds = pred_model.predict(sample_imgs)\n",
        "decoded_raw = decode_batch(preds)\n",
        "decoded = [collapse_repeats(t) for t in decoded_raw]\n",
        "\n",
        "for i in range(len(sample_imgs)):\n",
        "    plt.imshow(sample_imgs[i].squeeze(), cmap=\"gray\")\n",
        "    plt.title(f\"GT: {test_labels[i]}\\nPred: {decoded[i]}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ]
    }
  ]
}