{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language Model Integration for OCR\n",
        "\n",
        "This notebook explores the impact of statistical language models on handwritten text recognition accuracy using CTC decoding.\n"
      ],
      "metadata": {
        "id": "KiaRbsT_Zp-0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Motivation\n",
        "CTC-based OCR models often produce character-level predictions without linguistic context. Language models help correct improbable character sequences by incorporating word-level probabilities.\n"
      ],
      "metadata": {
        "id": "GqDTIQUkZwv5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation for Language Modeling\n"
      ],
      "metadata": {
        "id": "Mh-7Y96WZ2c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import re\n",
        "\n",
        "print(\"üì• Loading Teklia IAM-line dataset...\")\n",
        "dataset = load_dataset(\"teklia/IAM-line\")\n",
        "\n",
        "texts = []\n",
        "for split in dataset.keys():\n",
        "    for sample in dataset[split]:\n",
        "        text = sample[\"text\"].strip()\n",
        "        if len(text) > 3:\n",
        "            # ‚úÖ Fixed regex: move '-' to the end of the character set\n",
        "            text = re.sub(r\"[^a-zA-Z0-9.,!?;:'\\\"()\\- ]+\", \" \", text)\n",
        "            text = re.sub(r\"\\s+\", \" \", text).lower()\n",
        "            texts.append(text)\n",
        "\n",
        "print(f\"‚úÖ Extracted {len(texts)} lines from IAM-line dataset.\")\n",
        "\n",
        "# Save to corpus file\n",
        "with open(corpus_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(texts))\n",
        "\n",
        "print(f\"‚úÖ Corpus saved to: {corpus_path}\")\n",
        "!head -n 10 {corpus_path}"
      ],
      "metadata": {
        "id": "hE7xWVNjdIFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-Gram Language Model\n"
      ],
      "metadata": {
        "id": "XvFvnHATZ6dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kenlm/build/bin/lmplz --discount_fallback -o 5 < {corpus_path} > {lm_arpa_path}\n",
        "!kenlm/build/bin/build_binary {lm_arpa_path} {lm_binary_path}\n",
        "\n",
        "print(f\"\\n‚úÖ KenLM models created successfully:\")\n",
        "!ls -lh {lm_arpa_path} {lm_binary_path}\n"
      ],
      "metadata": {
        "id": "4rK60f_Yddpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import re\n",
        "\n",
        "print(\"üì• Loading Teklia IAM-line dataset...\")\n",
        "dataset = load_dataset(\"teklia/IAM-line\")\n",
        "\n",
        "texts = []\n",
        "for split in dataset.keys():\n",
        "    for sample in dataset[split]:\n",
        "        text = sample[\"text\"].strip()\n",
        "        if len(text) > 3:\n",
        "            # ‚úÖ Fixed regex: move '-' to the end of the character set\n",
        "            text = re.sub(r\"[^a-zA-Z0-9.,!?;:'\\\"()\\- ]+\", \" \", text)\n",
        "            text = re.sub(r\"\\s+\", \" \", text).lower()\n",
        "            texts.append(text)\n",
        "\n",
        "print(f\"‚úÖ Extracted {len(texts)} lines from IAM-line dataset.\")\n",
        "\n",
        "# Save to corpus file\n",
        "with open(corpus_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(texts))\n",
        "\n",
        "print(f\"‚úÖ Corpus saved to: {corpus_path}\")\n",
        "!head -n 10 {corpus_path}"
      ],
      "metadata": {
        "id": "DFrc9GIhe5Pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================================\n",
        "# üß† 1Ô∏è‚É£  Install dependencies\n",
        "# ===========================================\n",
        "!apt-get -qq install build-essential cmake\n",
        "!pip install datasets joblib\n",
        "\n",
        "# ===========================================\n",
        "# üß† 2Ô∏è‚É£  Clone & build KenLM\n",
        "# ===========================================\n",
        "!rm -rf /content/kenlm\n",
        "!git clone https://github.com/kpu/kenlm.git /content/kenlm\n",
        "!mkdir -p /content/kenlm/build\n",
        "%cd /content/kenlm/build\n",
        "!cmake /content/kenlm\n",
        "!make -j4\n",
        "!ls -l /content/kenlm/build/bin/\n",
        "\n",
        "# ===========================================\n",
        "# üß† 3Ô∏è‚É£  Create training corpus from Teklia IAM dataset\n",
        "# ===========================================\n",
        "%cd /content\n",
        "from datasets import load_dataset\n",
        "import re\n",
        "\n",
        "print(\"üì• Loading Teklia IAM dataset ...\")\n",
        "ds = load_dataset(\"teklia/iam-line\", split=\"train\")\n",
        "\n",
        "texts = []\n",
        "for ex in ds:\n",
        "    t = ex[\"text\"]\n",
        "    if len(t) > 3:\n",
        "        t = re.sub(r\"[^A-Za-z0-9.,!?;:'\\\"()\\- ]+\", \" \", t)\n",
        "        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n",
        "        texts.append(t)\n",
        "\n",
        "corpus_path = \"/content/iam_corpus.txt\"\n",
        "with open(corpus_path, \"w\") as f:\n",
        "    f.write(\"\\n\".join(texts))\n",
        "print(f\"‚úÖ Corpus saved: {corpus_path} ({len(texts)} lines)\")\n",
        "\n",
        "# ===========================================\n",
        "# üß† 4Ô∏è‚É£  Train a 3-gram KenLM language model\n",
        "# ===========================================\n",
        "!cd /content && /content/kenlm/build/bin/lmplz -o 3 < /content/iam_corpus.txt > /content/iam_lm.arpa\n",
        "!cd /content && /content/kenlm/build/bin/build_binary /content/iam_lm.arpa /content/iam_lm.binary\n",
        "print(\"‚úÖ KenLM binary built: /content/iam_lm.binary\")\n",
        "\n",
        "# ===========================================\n",
        "# üß† 5Ô∏è‚É£  Mount Drive & save LM model there\n",
        "# ===========================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/kenlm_iam_lm\n",
        "!cp /content/iam_lm.arpa /content/iam_lm.binary /content/drive/MyDrive/kenlm_iam_lm/\n",
        "print(\"‚úÖ Saved KenLM model to: /content/drive/MyDrive/kenlm_iam_lm\")\n"
      ],
      "metadata": {
        "id": "kOF4eQ1_fNTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = build_ctcdecoder(\n",
        "    labels=vocab_list,\n",
        "    kenlm_model_path=KENLM_BINARY,\n",
        ")\n",
        "print(\"‚úÖ KenLM decoder built successfully!\")\n"
      ],
      "metadata": {
        "id": "2tIhS4njfrhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üß† 1Ô∏è‚É£ Import dependencies\n",
        "# ============================================\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import joblib\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import tempfile\n",
        "from jiwer import wer, cer\n",
        "from pyctcdecode import build_ctcdecoder\n",
        "import pyctcdecode.decoder as decoder_module\n",
        "import pyctcdecode.language_model as language_model_module\n",
        "import kenlm\n",
        "\n",
        "# ‚úÖ Fix: Inject kenlm inside pyctcdecode (needed for Colab)\n",
        "decoder_module.kenlm = kenlm\n",
        "language_model_module.kenlm = kenlm\n",
        "print(\"‚úÖ KenLM successfully linked to pyctcdecode\")\n",
        "\n",
        "# ============================================\n",
        "# üß† 2Ô∏è‚É£ Paths ‚Äì update if needed\n",
        "# ============================================\n",
        "MODEL_DIR = \"/content/drive/MyDrive/htr_final_model_20251110_110833\"\n",
        "KENLM_BINARY = \"/content/drive/MyDrive/kenlm_iam_lm/iam_lm.binary\"\n",
        "\n",
        "# ============================================\n",
        "# üß† 3Ô∏è‚É£ Load HTR model + vocabulary\n",
        "# ============================================\n",
        "print(\"üîÑ Loading HTR model and vocab...\")\n",
        "model = keras.models.load_model(os.path.join(MODEL_DIR, \"htr_model.keras\"), compile=False)\n",
        "vocab_list = joblib.load(os.path.join(MODEL_DIR, \"vocab_list.pkl\"))\n",
        "print(f\"‚úÖ Model and vocabulary loaded successfully! (Vocab size: {len(vocab_list)})\")\n",
        "\n",
        "# ============================================\n",
        "# üß† 4Ô∏è‚É£ Build tuned KenLM decoder\n",
        "# ============================================\n",
        "print(\"üîÑ Building KenLM decoder (Œ±=0.5, Œ≤=1.5, beam_width=100)...\")\n",
        "decoder = build_ctcdecoder(\n",
        "    labels=vocab_list,\n",
        "    kenlm_model_path=KENLM_BINARY,\n",
        "    alpha=0.5,   # Tuned parameter\n",
        "    beta=1.5     # Tuned parameter\n",
        ")\n",
        "print(\"‚úÖ KenLM decoder initialized with tuned parameters!\")\n",
        "\n",
        "# ============================================\n",
        "# üß† 5Ô∏è‚É£ Line segmentation (Projection method)\n",
        "# ============================================\n",
        "def segment_lines_projection(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "    _, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    kernel = np.ones((2, 50), np.uint8)\n",
        "    closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
        "    hist = np.sum(closed, axis=1)\n",
        "    threshold = np.max(hist) * 0.1\n",
        "\n",
        "    lines, in_line, start = [], False, 0\n",
        "    for y, val in enumerate(hist):\n",
        "        if val > threshold and not in_line:\n",
        "            in_line, start = True, y\n",
        "        elif val <= threshold and in_line:\n",
        "            in_line = False\n",
        "            end = y\n",
        "            if end - start >= 10:\n",
        "                lines.append((start, end))\n",
        "\n",
        "    line_imgs = []\n",
        "    for y1, y2 in lines:\n",
        "        y1 = max(y1 - 10, 0)\n",
        "        y2 = min(y2 + 10, img.shape[0])\n",
        "        cropped = img[y1:y2, :]\n",
        "        pil_img = Image.fromarray(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))\n",
        "        line_imgs.append(pil_img)\n",
        "    return line_imgs\n",
        "\n",
        "# ============================================\n",
        "# üß† 6Ô∏è‚É£ Preprocess for HTR model\n",
        "# ============================================\n",
        "IMG_HEIGHT, IMG_WIDTH = 64, 800\n",
        "\n",
        "def preprocess_image(img):\n",
        "    img = img.convert(\"L\")\n",
        "    img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n",
        "    img = np.array(img, dtype=np.float32) / 255.0\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    return np.expand_dims(img, axis=0)\n",
        "\n",
        "# ============================================\n",
        "# üß† 7Ô∏è‚É£ Decoding functions\n",
        "# ============================================\n",
        "def decode_greedy(pred):\n",
        "    pred = np.squeeze(pred)\n",
        "    best_path = np.argmax(pred, axis=-1)\n",
        "    text = ''.join([vocab_list[i] for i in best_path if i < len(vocab_list)])\n",
        "    return text\n",
        "\n",
        "def decode_with_kenlm(pred):\n",
        "    pred = np.squeeze(pred)\n",
        "    return decoder.decode(pred, beam_width=100)  # Tuned beam width\n",
        "\n",
        "# ============================================\n",
        "# üß† 8Ô∏è‚É£ Gradio Prediction Function\n",
        "# ============================================\n",
        "def recognize_text(uploaded_image, ground_truth):\n",
        "    if uploaded_image is None:\n",
        "        return [], \"\", \"\", \"‚ö†Ô∏è Please upload a handwriting image.\"\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as tmp:\n",
        "        uploaded_image.save(tmp.name)\n",
        "        image_path = tmp.name\n",
        "\n",
        "    line_images = segment_lines_projection(image_path)\n",
        "    if not line_images:\n",
        "        return [], \"\", \"\", \"‚ùå No text lines detected.\"\n",
        "\n",
        "    results = []\n",
        "    greedy_lines, lm_lines = [], []\n",
        "\n",
        "    for line_img in line_images:\n",
        "        img_input = preprocess_image(line_img)\n",
        "        preds = model.predict(img_input, verbose=0)\n",
        "\n",
        "        greedy_text = decode_greedy(preds)\n",
        "        lm_text = decode_with_kenlm(preds)\n",
        "\n",
        "        results.append((line_img, f\"üßæ Greedy: {greedy_text}\\nüìñ LM: {lm_text}\"))\n",
        "        greedy_lines.append(greedy_text)\n",
        "        lm_lines.append(lm_text)\n",
        "\n",
        "    greedy_final = \"\\n\".join(greedy_lines)\n",
        "    lm_final = \"\\n\".join(lm_lines)\n",
        "\n",
        "    if ground_truth.strip():\n",
        "        return results, greedy_final, lm_final, (\n",
        "            f\"WER (Greedy): {wer(ground_truth, greedy_final):.2%} | CER: {cer(ground_truth, greedy_final):.2%}\\n\"\n",
        "            f\"WER (KenLM): {wer(ground_truth, lm_final):.2%} | CER: {cer(ground_truth, lm_final):.2%}\"\n",
        "        )\n",
        "    else:\n",
        "        return results, greedy_final, lm_final, \"‚ÑπÔ∏è No ground truth provided.\"\n",
        "\n",
        "# ============================================\n",
        "# üß† 9Ô∏è‚É£ Gradio Interface\n",
        "# ============================================\n",
        "with gr.Blocks(title=\"HTR + Tuned KenLM Handwriting Recognition\") as interface:\n",
        "    gr.Markdown(\"## üìù Handwritten Text Recognition (Greedy vs Tuned KenLM)\")\n",
        "    gr.Markdown(\"Upload a handwritten image ‚Äî the app will segment text lines and show both raw CTC and tuned LM predictions.\")\n",
        "\n",
        "    upload = gr.Image(type=\"pil\", label=\"üì§ Upload Handwritten Image\")\n",
        "    ground_truth_input = gr.Textbox(label=\"‚úÖ Ground Truth (optional for accuracy)\", lines=4)\n",
        "    recognize_btn = gr.Button(\"üß† Recognize Text\")\n",
        "\n",
        "    gallery = gr.Gallery(label=\"üì∏ Line Predictions\", columns=1, preview=True)\n",
        "    greedy_output = gr.Textbox(label=\"üîπ Greedy Decode (No LM)\")\n",
        "    lm_output = gr.Textbox(label=\"üîπ Tuned KenLM Decode (Œ±=0.5, Œ≤=1.5, beam=100)\")\n",
        "    accuracy_output = gr.Textbox(label=\"üìä Accuracy Comparison (WER / CER)\")\n",
        "\n",
        "    recognize_btn.click(\n",
        "        fn=recognize_text,\n",
        "        inputs=[upload, ground_truth_input],\n",
        "        outputs=[gallery, greedy_output, lm_output, accuracy_output]\n",
        "    )\n",
        "\n",
        "interface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "JANOPKr0eAka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-Gram Evaluation\n"
      ],
      "metadata": {
        "id": "d9g-b1bvaDTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üì¶ 1Ô∏è‚É£ Install dependencies\n",
        "# ============================================\n",
        "!apt-get install -y cmake build-essential libboost-all-dev\n",
        "!pip install pyctcdecode https://github.com/kpu/kenlm/archive/master.zip jiwer datasets joblib matplotlib tqdm\n",
        "\n",
        "# ============================================\n",
        "# üß† 2Ô∏è‚É£ Import libraries\n",
        "# ============================================\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import joblib\n",
        "from pyctcdecode import build_ctcdecoder\n",
        "import pyctcdecode.decoder as decoder_module\n",
        "import pyctcdecode.language_model as language_model_module\n",
        "import kenlm\n",
        "from jiwer import wer, cer\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "\n",
        "# Inject kenlm bindings to pyctcdecode\n",
        "decoder_module.kenlm = kenlm\n",
        "language_model_module.kenlm = kenlm\n",
        "print(\"‚úÖ KenLM successfully linked to pyctcdecode\")\n",
        "\n",
        "# ============================================\n",
        "# üìÅ 3Ô∏è‚É£ Paths (same as Gradio setup)\n",
        "# ============================================\n",
        "MODEL_DIR = \"/content/drive/MyDrive/htr_final_model_20251110_110833\"\n",
        "KENLM_BINARY = \"/content/drive/MyDrive/kenlm_iam_lm/iam_lm.binary\"\n",
        "\n",
        "# ============================================\n",
        "# üß† 4Ô∏è‚É£ Load model + vocab\n",
        "# ============================================\n",
        "print(\"üîÑ Loading model and vocab...\")\n",
        "model = keras.models.load_model(os.path.join(MODEL_DIR, \"htr_model.keras\"), compile=False)\n",
        "vocab_list = joblib.load(os.path.join(MODEL_DIR, \"vocab_list.pkl\"))\n",
        "print(f\"‚úÖ Model loaded successfully! Vocab size: {len(vocab_list)}\")\n",
        "\n",
        "# ============================================\n",
        "# üß† 5Ô∏è‚É£ Build KenLM decoder\n",
        "# ============================================\n",
        "print(\"üîÑ Building KenLM decoder...\")\n",
        "decoder = build_ctcdecoder(labels=vocab_list, kenlm_model_path=KENLM_BINARY)\n",
        "print(\"‚úÖ KenLM decoder ready!\")\n",
        "\n",
        "# ============================================\n",
        "# üìö 6Ô∏è‚É£ Load IAM Line dataset\n",
        "# ============================================\n",
        "print(\"üìÇ Loading IAM Line dataset (test split)...\")\n",
        "dataset = load_dataset(\"Teklia/IAM-line\", split=\"test\")\n",
        "print(f\"‚úÖ Loaded {len(dataset)} samples.\")\n",
        "\n",
        "# ============================================\n",
        "# üß© 7Ô∏è‚É£ Preprocessing\n",
        "# ============================================\n",
        "IMG_HEIGHT, IMG_WIDTH = 64, 800\n",
        "\n",
        "def preprocess_image(example):\n",
        "    \"\"\"Handle the fact that 'image' is already a PIL object in IAM Line dataset.\"\"\"\n",
        "    img = example[\"image\"].convert(\"L\")\n",
        "    img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n",
        "    img = np.expand_dims(np.array(img, dtype=np.float32) / 255.0, axis=-1)\n",
        "    return np.expand_dims(img, axis=0), example[\"text\"]\n",
        "\n",
        "# ============================================\n",
        "# üßÆ 8Ô∏è‚É£ Evaluate both Greedy + KenLM decoding\n",
        "# ============================================\n",
        "def decode_greedy(pred):\n",
        "    pred = np.squeeze(pred)\n",
        "    best_path = np.argmax(pred, axis=-1)\n",
        "    return ''.join([vocab_list[i] for i in best_path if i < len(vocab_list)])\n",
        "\n",
        "def decode_with_kenlm(pred):\n",
        "    pred = np.squeeze(pred)\n",
        "    return decoder.decode(pred)\n",
        "\n",
        "greedy_preds, lm_preds, gts = [], [], []\n",
        "\n",
        "for ex in tqdm(dataset, desc=\"Evaluating\"):\n",
        "    img_input, gt = preprocess_image(ex)\n",
        "    preds = model.predict(img_input, verbose=0)\n",
        "    greedy_preds.append(decode_greedy(preds))\n",
        "    lm_preds.append(decode_with_kenlm(preds))\n",
        "    gts.append(gt)\n",
        "\n",
        "# ============================================\n",
        "# üìä 9Ô∏è‚É£ Compute metrics\n",
        "# ============================================\n",
        "greedy_wer = np.mean([wer(gt, p) for gt, p in zip(gts, greedy_preds)])\n",
        "greedy_cer = np.mean([cer(gt, p) for gt, p in zip(gts, greedy_preds)])\n",
        "lm_wer = np.mean([wer(gt, p) for gt, p in zip(gts, lm_preds)])\n",
        "lm_cer = np.mean([cer(gt, p) for gt, p in zip(gts, lm_preds)])\n",
        "\n",
        "print(\"\\nüìä Evaluation Summary:\")\n",
        "print(f\"üßÆ Greedy Decode ‚Üí WER: {greedy_wer:.4f}, CER: {greedy_cer:.4f}\")\n",
        "print(f\"üìñ KenLM Decode  ‚Üí WER: {lm_wer:.4f}, CER: {lm_cer:.4f}\")\n",
        "\n",
        "# ============================================\n",
        "# üñº üîü Show sample predictions\n",
        "# ============================================\n",
        "for i in range(5):\n",
        "    plt.imshow(dataset[i][\"image\"], cmap=\"gray\")\n",
        "    plt.title(f\"GT: {gts[i]}\\nGreedy: {greedy_preds[i]}\\nLM: {lm_preds[i]}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "-MaDkVmqfw7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from jiwer import wer, cer\n",
        "\n",
        "# ‚úÖ Make sure these lists exist in your notebook:\n",
        "# gts, greedy_preds, lm_preds\n",
        "\n",
        "# Build detailed DataFrame\n",
        "results_df = pd.DataFrame({\n",
        "    \"GroundTruth\": gts,\n",
        "    \"GreedyPrediction\": greedy_preds,\n",
        "    \"KenLMPrediction\": lm_preds,\n",
        "    \"Greedy_WER\": [wer(gt, p) for gt, p in zip(gts, greedy_preds)],\n",
        "    \"Greedy_CER\": [cer(gt, p) for gt, p in zip(gts, greedy_preds)],\n",
        "    \"LM_WER\": [wer(gt, p) for gt, p in zip(gts, lm_preds)],\n",
        "    \"LM_CER\": [cer(gt, p) for gt, p in zip(gts, lm_preds)]\n",
        "})\n",
        "\n",
        "# Save to your Google Drive model directory\n",
        "save_path = \"/content/drive/MyDrive/htr_final_model_20251110_110833/evaluation_results.csv\"\n",
        "results_df.to_csv(save_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Evaluation results saved successfully to:\\n{save_path}\")\n",
        "print(f\"üìÑ Total lines saved: {len(results_df)}\")\n"
      ],
      "metadata": {
        "id": "N-N6A0KYf-uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Load your saved CSV\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/htr_final_model_20251110_110833/evaluation_results.csv\")\n",
        "\n",
        "# Histogram of WERs\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(df[\"Greedy_WER\"], color=\"red\", label=\"Greedy\", kde=True)\n",
        "sns.histplot(df[\"LM_WER\"], color=\"blue\", label=\"KenLM\", kde=True)\n",
        "plt.title(\"WER Distribution: Greedy vs KenLM\")\n",
        "plt.xlabel(\"WER per line\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Bar comparison of average performance\n",
        "plt.figure(figsize=(6,4))\n",
        "bars = plt.bar([\"Greedy WER\", \"KenLM WER\", \"Greedy CER\", \"KenLM CER\"],\n",
        "               [df[\"Greedy_WER\"].mean(), df[\"LM_WER\"].mean(),\n",
        "                df[\"Greedy_CER\"].mean(), df[\"LM_CER\"].mean()],\n",
        "               color=[\"salmon\", \"skyblue\", \"salmon\", \"skyblue\"])\n",
        "plt.title(\"Average WER & CER Comparison\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kkZYyjxef_nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5-Gram Language Model\n"
      ],
      "metadata": {
        "id": "aIv4AHYbaHtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üß© STEP 0: Install dependencies\n",
        "# ============================================\n",
        "!apt install -y build-essential libboost-all-dev cmake\n",
        "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "!pip install pyctcdecode jiwer datasets joblib matplotlib tqdm\n",
        "\n",
        "# ============================================\n",
        "# üìö STEP 1: Load IAM Line training data\n",
        "# ============================================\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "\n",
        "print(\"üîÑ Loading IAM Line dataset...\")\n",
        "dataset = load_dataset(\"teklia/iam-line\")  # ‚úÖ Correct name\n",
        "\n",
        "train_texts = [ex[\"text\"].strip() for ex in dataset[\"train\"] if ex[\"text\"].strip()]\n",
        "print(f\"‚úÖ Loaded {len(train_texts)} training lines.\")\n",
        "\n",
        "# Save corpus to Drive\n",
        "os.makedirs(\"/content/drive/MyDrive/\", exist_ok=True)\n",
        "corpus_path = \"/content/drive/MyDrive/iam_corpus.txt\"\n",
        "\n",
        "with open(corpus_path, \"w\") as f:\n",
        "    for line in train_texts:\n",
        "        f.write(line + \"\\n\")\n",
        "\n",
        "print(f\"‚úÖ Saved corpus to: {corpus_path}\")\n",
        "\n",
        "# ============================================\n",
        "# üß† STEP 2: Build 5-gram KenLM\n",
        "# ============================================\n",
        "!git clone https://github.com/kpu/kenlm.git\n",
        "!mkdir -p kenlm/build && cd kenlm/build && cmake .. && make -j4\n",
        "\n",
        "lm_path = \"/content/drive/MyDrive/iam_lm_5gram.arpa\"\n",
        "!kenlm/build/bin/lmplz -o 5 < /content/drive/MyDrive/iam_corpus.txt > {lm_path}\n",
        "\n",
        "print(f\"‚úÖ 5-gram KenLM saved to: {lm_path}\")\n",
        "\n",
        "# ============================================\n",
        "# üß± STEP 3: Load HTR model + vocab\n",
        "# ============================================\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import joblib\n",
        "from pyctcdecode import build_ctcdecoder\n",
        "import pyctcdecode.decoder as decoder_module\n",
        "import pyctcdecode.language_model as language_model_module\n",
        "import kenlm\n",
        "\n",
        "# Inject kenlm bindings for pyctcdecode\n",
        "decoder_module.kenlm = kenlm\n",
        "language_model_module.kenlm = kenlm\n",
        "print(\"‚úÖ KenLM successfully linked to pyctcdecode\")\n",
        "\n",
        "MODEL_DIR = \"/content/drive/MyDrive/htr_final_model_20251110_110833\"\n",
        "\n",
        "print(\"üîÑ Loading model and vocab...\")\n",
        "model = keras.models.load_model(os.path.join(MODEL_DIR, \"htr_model.keras\"), compile=False)\n",
        "vocab_list = joblib.load(os.path.join(MODEL_DIR, \"vocab_list.pkl\"))\n",
        "print(f\"‚úÖ Model loaded successfully! Vocab size: {len(vocab_list)}\")\n",
        "\n",
        "# ============================================\n",
        "# üî§ STEP 4: Build 5-gram LM decoder\n",
        "# ============================================\n",
        "decoder = build_ctcdecoder(labels=vocab_list, kenlm_model_path=lm_path)\n",
        "print(\"‚úÖ 5-gram KenLM decoder ready!\")"
      ],
      "metadata": {
        "id": "a9JB7psZgO6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WER Comparison and Analysis\n"
      ],
      "metadata": {
        "id": "eiQMh-GTaKpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üßÆ STEP 5: Evaluate model on IAM Line test set\n",
        "# ============================================\n",
        "from jiwer import wer, cer\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(example):\n",
        "    # ‚úÖ The dataset image is already a PIL.Image object\n",
        "    img = example[\"image\"].convert(\"L\")  # grayscale\n",
        "    img = img.resize((800, 64))\n",
        "    img = np.array(img, dtype=np.float32) / 255.0\n",
        "    img = np.expand_dims(img, axis=(0, -1))  # add batch & channel dims\n",
        "    return img, example[\"text\"]\n",
        "\n",
        "def decode_greedy(pred):\n",
        "    pred = np.squeeze(pred)\n",
        "    best_path = np.argmax(pred, axis=-1)\n",
        "    return \"\".join([vocab_list[i] for i in best_path if i < len(vocab_list)])\n",
        "\n",
        "print(\"üìÇ Loading IAM test split...\")\n",
        "test_data = dataset[\"test\"]\n",
        "print(f\"‚úÖ Loaded {len(test_data)} samples.\")\n",
        "\n",
        "greedy_preds, lm_preds, gts = [], [], []\n",
        "\n",
        "for ex in tqdm(test_data, desc=\"Evaluating\"):\n",
        "    img_input, gt = preprocess_image(ex)\n",
        "    preds = model.predict(img_input, verbose=0)\n",
        "    greedy_preds.append(decode_greedy(preds))\n",
        "    lm_preds.append(decoder.decode(np.squeeze(preds)))\n",
        "    gts.append(gt)\n",
        "\n",
        "# ============================================\n",
        "# üìä STEP 6: Compute WER/CER\n",
        "# ============================================\n",
        "greedy_wer = wer(gts, greedy_preds)\n",
        "greedy_cer = cer(gts, greedy_preds)\n",
        "lm_wer = wer(gts, lm_preds)\n",
        "lm_cer = cer(gts, lm_preds)\n",
        "\n",
        "print(\"\\nüìä Evaluation Summary:\")\n",
        "print(f\"üßÆ Greedy Decode ‚Üí WER: {greedy_wer:.4f}, CER: {greedy_cer:.4f}\")\n",
        "print(f\"üìñ 5-gram LM Decode ‚Üí WER: {lm_wer:.4f}, CER: {lm_cer:.4f}\")\n",
        "\n",
        "# ============================================\n",
        "# üíæ STEP 7: Save all artifacts\n",
        "# ============================================\n",
        "print(f\"‚úÖ All artifacts saved:\")\n",
        "print(f\"  üìú Corpus: {corpus_path}\")\n",
        "print(f\"  üß† 5-gram LM: {lm_path}\")\n"
      ],
      "metadata": {
        "id": "UX1k5SaPgPkt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}